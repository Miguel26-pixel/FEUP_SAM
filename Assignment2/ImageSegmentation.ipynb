{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimedia Services and Applications - Image Processing in Python\n",
    "\n",
    "## Objectives\n",
    "This practical assignment intends to apply and consolidate the knowledge gained concerning image processing techniques to process and improve images.\n",
    "\n",
    "## Introduction\n",
    "The objective of this laboratory assignment is to allow the student to experiment further digital processing techniques of visual signals, using Python and the OpenCV library.\n",
    "\n",
    "To conduct the proposed experiments, we will use Python scripts and images available on the course platform. Images will be used as input data to those scripts. The output will consist of processed versions of those images, which should be analyzed by the student to interpret the effects of the conducted processing operations. The majority of those images has the bitmap format (.bmp) which means that each pixel is represented by three RGB eight-bit values, so in total 24 bits per pixel.\n",
    "\n",
    "Note: the symbol ‚úç means that you should include in your report graphics or images resulting from the operated processing or code that you may have developed. The symbol üïµ indicates that you should include in your report a brief analysis of the results you have obtained.\n",
    "\n",
    "## Resources\n",
    "1. We will use the OpenCV library for the image processing tasks. To install the OpenCV library, you can use the following bash command (inside the SAM conda environment):\n",
    "\n",
    "```\n",
    "pip install opencv-python\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# Boilerplate code\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# The following line has to output SAM, otherwise it means that the right\n",
    "# conda environment is not being activated\n",
    "print (os.environ['CONDA_DEFAULT_ENV']) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You may depart from the following code example `segment_SAM_example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_name = \"christmasBB\"\n",
    "\n",
    "# Read input image\n",
    "image = cv2.imread(f'./images/{image_name}.jpg')\n",
    "\n",
    "# Check if the image has three channels (RGB)\n",
    "if len(image.shape) == 3:\n",
    "    height, width, planes = image.shape\n",
    "    b, g, r = cv2.split(image)\n",
    "# else You need a RGB image\n",
    "# Show RGB components\n",
    "plt.imshow(cv2.merge((r, g, b)))\n",
    "plt.title('RGB components');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Blue channel histogram\n",
    "plt.hist(b.ravel(), 256, [0, 256])\n",
    "plt.title('Blue channel histogram');\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analysing this histogram, you pick a specific value for the threshold. (Try with different values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BW segmentation\n",
    "BWforeground = np.where(b < threshold, 255, 0)\n",
    "plt.imshow(BWforeground, cmap='gray')\n",
    "plt.title('B&W segmented image');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to show the full-color representation of the foreground objects we do the following operations: a) applying a binary mask to an image and b) converting the color space of the resulting image for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying a binary mask\n",
    "# The mask is applied by converting BWforeground to an 8-bit unsigned integer (np.uint8), as OpenCV expects masks to be of this data type.\n",
    "foreground = cv2.bitwise_and(image, image, mask=BWforeground.astype(np.uint8))\n",
    "# Display Image\n",
    "plt.imshow(cv2.cvtColor(foreground, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Colored foreground');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see an alternative example, based on the _blueness_ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative using the blueness factor\n",
    "\n",
    "# This line computes the blueness factor for each pixel in the image by subtracting \n",
    "# the maximum value of the red and green channels from the blue channel value.\n",
    "blueness = b.astype(np.float64) - np.maximum(r.astype(np.float64), g.astype(np.float64))\n",
    "\n",
    "fig, axs = plt.subplots(2,1)\n",
    "# Visualize the blueness image\n",
    "axs[0].imshow(blueness, cmap='gray')\n",
    "axs[0].set_title('Blueness channel')\n",
    "\n",
    "# Plot the histogram of the blueness channel\n",
    "axs[1].hist(blueness.ravel(), 256, [0, np.max(blueness)])\n",
    "axs[1].set_title('Histogram')\n",
    "axs[1].set_xlabel('Blueness value')\n",
    "axs[1].set_ylabel('Frequency');\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 60\n",
    "BWforegroundBlueness = blueness < threshold\n",
    "plt.imshow(BWforegroundBlueness, cmap='gray')\n",
    "plt.title('B&W segmented image using blueness');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the full-color representation of the foreground objects\n",
    "foreground_bl = cv2.bitwise_and(image, image, mask=BWforegroundBlueness.astype(np.uint8))\n",
    "plt.imshow(cv2.cvtColor(foreground_bl, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Colored foreground using blueness');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a new image by superimposing the segmented objects\n",
    "new_background_name = 'birdBB'\n",
    "output_image_path=f'./images/segmented_over_{new_background_name}.jpg'\n",
    "# Read input image\n",
    "new_background = cv2.imread(f'./images/{new_background_name}.jpg')\n",
    "# Resize new_background to match the size of foreground_bl\n",
    "new_background_resized = cv2.resize(new_background, (foreground_bl.shape[1], foreground_bl.shape[0]))\n",
    "# Perform the weighted addition\n",
    "output_image = cv2.addWeighted(new_background_resized, 0.5, foreground_bl, 0.5, 0)\n",
    "plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Fused image');\n",
    "# Save the Image\n",
    "cv2.imwrite(output_image_path, output_image)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work to be developed\n",
    "\n",
    "On TV weather news, what the viewer normally sees is the weather forecast person standing in front of maps. In traditional news production, they just stand in front of a blue (or green) wall. Put in simple manner, a special system extracts the person (the ‚Äúweatherman‚Äô‚Äù) from the images and adds her/ him in front of the real weather related images. The basic idea of this system is to split an image into RGB channels, create a mask based on the information of the blue channel, and use this mask to extract images. In this assignment, you will develop a script that is able to do just this.\n",
    "\n",
    "### 1.1 Basic segmentation:\n",
    "\n",
    "Based on the code `segment_SAM_example`, write a Python script (or jupyter-notebook) ‚úç that:\n",
    "\n",
    "* imports a coloured image with a blue background and presents that image on the screen;\n",
    "* separates each RGB component in a different matrix and visualises each one on the screen;\n",
    "* uses the matrix with the B component to identify the foreground objects (the jumping man or the Christmas bulbs or the bird). One possibility for doing this is to inspect the values of the B matrix: high values will correspond to the background. If we set up a threshold with a value just below those higher values, all the pixels that have a value lower than the threshold in principle will belong to the foreground (they will represent the foreground objects, i.e., the jumping man, the christmas bulbs or the bird). Using that threshold, copy from the B matrix to a new matrix (with the same dimensions) only the pixel values that are below that threshold. When doing that you may put those pixels with the value 255 and all the others with value 0 (you will create a black and white picture). To decide on the threshold, instead of looking directly at the values of the B matrix, you may generate the histogram with the built-in function `cv2.calcHist` (or other that you may prefer) and by inspecting visually the histogram decide on a suitable threshold value (the script may ask the user to input that value).\n",
    "* shows the black and white segmented image on the screen and creates in the disk a new file with that image.\n",
    "* Make experiments with different threshold values and with different images. Interpret the results and comment the results taking into consideration that you have used only the blue channel. \n",
    "* üïµ **Could there be low blue value in zones of the background? Could there be high blue values in some parts of the foreground objects? Is it always true that a pixel with a high value in the B component is always blue?**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Alternative segmentation:\n",
    "\n",
    "Based on the code `segment_SAM_example`, write a Python script (or jupyter-notebook) ‚úç that:\n",
    "\n",
    "* imports a coloured image with a blue background and presents that image on the screen;\n",
    "* separates each RGB component in a different matrix and visualises each one on the screen;\n",
    "* Considering that a pixel is really blue if it has high values in the B component and low values in the other components, computes the ‚Äúblueness‚Äù of a pixel using the equation `blueness=B‚àímax(R,G)`.\n",
    "* selects a threshold based on the blueness factor (adopt the procedure explained above) and creates a new black and white image with the pixels of the foreground objects with value 255 and all the other with value zero (adopt the procedure explained above).\n",
    "* shows the black and white segmented image on the screen and creates in the disk a new file with that image.\n",
    "* üïµ **Compare these results with the original ones. Which are the better, and why?** \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adding objects to another image\n",
    "\n",
    "In this part you will use the segmented images that have been generated by your previous scripts to create a new image with the superimposition of the segmented image with a new image.\n",
    "\n",
    "* Use the OpenCV function `cv2.addWeighted()` to achieve that. The function blends the images by calculating a weighted sum of each pixel value, with the weight being determined by a scalar alpha value for each image. You may see the example above.\n",
    "* Modify your previous script(s) to generate a coloured segmented image and not only a black and white version.\n",
    "* üïµ **Experiment with different images and comment on your results** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables:\n",
    "\n",
    "- Deliver your code and a short report condensing your answers, images, and comments to your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
